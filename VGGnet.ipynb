{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/legend13/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:295: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = { \"A\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "        \"B\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "        \"D\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"],\n",
    "        \"E\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, 256, \"M\", 512, 512, 512, 512, \"M\", 512, 512, 512, 512, \"M\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGGnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    # VGG 초기화 Method\n",
    "    def __init__(self, cfg, batch_norm, num_classes = 1000, init_weights = True, drop_p = 0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = self.make_layers(cfg, batch_norm)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7)) \n",
    "        self.classifier = nn.Sequential(nn.Linear(512 * 7 * 7, 4096),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout(p=drop_p),\n",
    "                                        nn.Linear(4096, 4096),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Dropout(p=drop_p),\n",
    "                                        nn.Linear(4096, num_classes))\n",
    "\n",
    "        if init_weights:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "                elif isinstance(m, nn.Linear):\n",
    "                    nn.init.normal_(m.weight, 0, 0.01)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def make_layers(self, cfg, batch_norm = False):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for v in cfg: # cfg = [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"]\n",
    "            if type(v) == int:\n",
    "                if batch_norm:\n",
    "                    layers += [nn.Conv2d(in_channels, v, 3, padding=1), # 어차피 BN에 bias 포함\n",
    "                               nn.BatchNorm2d(v),\n",
    "                               nn.ReLU()]\n",
    "                else:\n",
    "                    layers += [nn.Conv2d(in_channels, v, 3, padding=1),\n",
    "                               nn.ReLU()]\n",
    "                in_channels = v\n",
    "            else:\n",
    "                layers += [nn.MaxPool2d(2)]\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 4])\n",
      "tensor([[[[ 0.9711,  0.9711,  2.6029,  2.6029],\n",
      "          [ 0.9711,  0.9711,  2.6029,  2.6029],\n",
      "          [-0.4300, -0.4300, -1.4447, -1.4447],\n",
      "          [-0.4300, -0.4300, -1.4447, -1.4447]],\n",
      "\n",
      "         [[-0.0884, -0.0884, -0.6124, -0.6124],\n",
      "          [-0.0884, -0.0884, -0.6124, -0.6124],\n",
      "          [-1.2006, -1.2006, -0.9367, -0.9367],\n",
      "          [-1.2006, -1.2006, -0.9367, -0.9367]],\n",
      "\n",
      "         [[ 1.6828,  1.6828,  1.3609,  1.3609],\n",
      "          [ 1.6828,  1.6828,  1.3609,  1.3609],\n",
      "          [ 0.1269,  0.1269, -0.0492, -0.0492],\n",
      "          [ 0.1269,  0.1269, -0.0492, -0.0492]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5927,  0.5927,  1.1156,  1.1156],\n",
      "          [ 0.5927,  0.5927,  1.1156,  1.1156],\n",
      "          [-0.7794, -0.7794,  0.6039,  0.6039],\n",
      "          [-0.7794, -0.7794,  0.6039,  0.6039]],\n",
      "\n",
      "         [[ 0.4624,  0.4624, -0.5096, -0.5096],\n",
      "          [ 0.4624,  0.4624, -0.5096, -0.5096],\n",
      "          [-0.2471, -0.2471, -1.0650, -1.0650],\n",
      "          [-0.2471, -0.2471, -1.0650, -1.0650]],\n",
      "\n",
      "         [[ 0.1031,  0.1031,  1.5149,  1.5149],\n",
      "          [ 0.1031,  0.1031,  1.5149,  1.5149],\n",
      "          [-0.2189, -0.2189, -0.8497, -0.8497],\n",
      "          [-0.2189, -0.2189, -0.8497, -0.8497]]]])\n"
     ]
    }
   ],
   "source": [
    "avgpool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "print(avgpool(torch.randn(2,3,32,32)).shape)\n",
    "x = torch.randn(2,3,2,2)\n",
    "print(avgpool(x)) # 작은 놈이 들어오면 늘려서라도 맞춰준다 # 값을 복제 시켜놓음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sequential(\n",
       "   (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=3, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=3, out_features=3, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (3): Linear(in_features=3, out_features=10, bias=True)\n",
       " ),\n",
       " Linear(in_features=2, out_features=2, bias=True),\n",
       " ReLU(),\n",
       " Sequential(\n",
       "   (0): Linear(in_features=2, out_features=3, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Linear(in_features=3, out_features=3, bias=True)\n",
       "   (3): ReLU()\n",
       " ),\n",
       " Linear(in_features=2, out_features=3, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=3, out_features=3, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=3, out_features=10, bias=True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(2,2),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Sequential(nn.Linear(2,3),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(3,3),\n",
    "                                    nn.ReLU()),\n",
    "                      nn.Linear(3,10))\n",
    "[m for m in model.modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = nn.Sequential([nn.Linear(1,1),\n",
    "#                        nn.Linear(1,1)]) # 리스트를 넣으면 안돼요!\n",
    "\n",
    "model2 = nn.Sequential(nn.Linear(1,1),\n",
    "                       nn.Linear(1,1))\n",
    "\n",
    "# print(*[1,2])\n",
    "# print([1,2])\n",
    "\n",
    "# model3 = nn.Sequential(nn.Linear(1,1),\n",
    "#                         nn.Linear(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "VGG                                      [2, 1000]                 --\n",
       "├─Sequential: 1-1                        [2, 512, 7, 7]            --\n",
       "│    └─Conv2d: 2-1                       [2, 64, 224, 224]         1,792\n",
       "│    └─BatchNorm2d: 2-2                  [2, 64, 224, 224]         128\n",
       "│    └─ReLU: 2-3                         [2, 64, 224, 224]         --\n",
       "│    └─Conv2d: 2-4                       [2, 64, 224, 224]         36,928\n",
       "│    └─BatchNorm2d: 2-5                  [2, 64, 224, 224]         128\n",
       "│    └─ReLU: 2-6                         [2, 64, 224, 224]         --\n",
       "│    └─MaxPool2d: 2-7                    [2, 64, 112, 112]         --\n",
       "│    └─Conv2d: 2-8                       [2, 128, 112, 112]        73,856\n",
       "│    └─BatchNorm2d: 2-9                  [2, 128, 112, 112]        256\n",
       "│    └─ReLU: 2-10                        [2, 128, 112, 112]        --\n",
       "│    └─Conv2d: 2-11                      [2, 128, 112, 112]        147,584\n",
       "│    └─BatchNorm2d: 2-12                 [2, 128, 112, 112]        256\n",
       "│    └─ReLU: 2-13                        [2, 128, 112, 112]        --\n",
       "│    └─MaxPool2d: 2-14                   [2, 128, 56, 56]          --\n",
       "│    └─Conv2d: 2-15                      [2, 256, 56, 56]          295,168\n",
       "│    └─BatchNorm2d: 2-16                 [2, 256, 56, 56]          512\n",
       "│    └─ReLU: 2-17                        [2, 256, 56, 56]          --\n",
       "│    └─Conv2d: 2-18                      [2, 256, 56, 56]          590,080\n",
       "│    └─BatchNorm2d: 2-19                 [2, 256, 56, 56]          512\n",
       "│    └─ReLU: 2-20                        [2, 256, 56, 56]          --\n",
       "│    └─Conv2d: 2-21                      [2, 256, 56, 56]          590,080\n",
       "│    └─BatchNorm2d: 2-22                 [2, 256, 56, 56]          512\n",
       "│    └─ReLU: 2-23                        [2, 256, 56, 56]          --\n",
       "│    └─Conv2d: 2-24                      [2, 256, 56, 56]          590,080\n",
       "│    └─BatchNorm2d: 2-25                 [2, 256, 56, 56]          512\n",
       "│    └─ReLU: 2-26                        [2, 256, 56, 56]          --\n",
       "│    └─MaxPool2d: 2-27                   [2, 256, 28, 28]          --\n",
       "│    └─Conv2d: 2-28                      [2, 512, 28, 28]          1,180,160\n",
       "│    └─BatchNorm2d: 2-29                 [2, 512, 28, 28]          1,024\n",
       "│    └─ReLU: 2-30                        [2, 512, 28, 28]          --\n",
       "│    └─Conv2d: 2-31                      [2, 512, 28, 28]          2,359,808\n",
       "│    └─BatchNorm2d: 2-32                 [2, 512, 28, 28]          1,024\n",
       "│    └─ReLU: 2-33                        [2, 512, 28, 28]          --\n",
       "│    └─Conv2d: 2-34                      [2, 512, 28, 28]          2,359,808\n",
       "│    └─BatchNorm2d: 2-35                 [2, 512, 28, 28]          1,024\n",
       "│    └─ReLU: 2-36                        [2, 512, 28, 28]          --\n",
       "│    └─Conv2d: 2-37                      [2, 512, 28, 28]          2,359,808\n",
       "│    └─BatchNorm2d: 2-38                 [2, 512, 28, 28]          1,024\n",
       "│    └─ReLU: 2-39                        [2, 512, 28, 28]          --\n",
       "│    └─MaxPool2d: 2-40                   [2, 512, 14, 14]          --\n",
       "│    └─Conv2d: 2-41                      [2, 512, 14, 14]          2,359,808\n",
       "│    └─BatchNorm2d: 2-42                 [2, 512, 14, 14]          1,024\n",
       "│    └─ReLU: 2-43                        [2, 512, 14, 14]          --\n",
       "│    └─Conv2d: 2-44                      [2, 512, 14, 14]          2,359,808\n",
       "│    └─BatchNorm2d: 2-45                 [2, 512, 14, 14]          1,024\n",
       "│    └─ReLU: 2-46                        [2, 512, 14, 14]          --\n",
       "│    └─Conv2d: 2-47                      [2, 512, 14, 14]          2,359,808\n",
       "│    └─BatchNorm2d: 2-48                 [2, 512, 14, 14]          1,024\n",
       "│    └─ReLU: 2-49                        [2, 512, 14, 14]          --\n",
       "│    └─Conv2d: 2-50                      [2, 512, 14, 14]          2,359,808\n",
       "│    └─BatchNorm2d: 2-51                 [2, 512, 14, 14]          1,024\n",
       "│    └─ReLU: 2-52                        [2, 512, 14, 14]          --\n",
       "│    └─MaxPool2d: 2-53                   [2, 512, 7, 7]            --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [2, 512, 7, 7]            --\n",
       "├─Sequential: 1-3                        [2, 1000]                 --\n",
       "│    └─Linear: 2-54                      [2, 4096]                 102,764,544\n",
       "│    └─ReLU: 2-55                        [2, 4096]                 --\n",
       "│    └─Dropout: 2-56                     [2, 4096]                 --\n",
       "│    └─Linear: 2-57                      [2, 4096]                 16,781,312\n",
       "│    └─ReLU: 2-58                        [2, 4096]                 --\n",
       "│    └─Dropout: 2-59                     [2, 4096]                 --\n",
       "│    └─Linear: 2-60                      [2, 1000]                 4,097,000\n",
       "==========================================================================================\n",
       "Total params: 143,678,248\n",
       "Trainable params: 143,678,248\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 39.29\n",
       "==========================================================================================\n",
       "Input size (MB): 1.20\n",
       "Forward/backward pass size (MB): 475.41\n",
       "Params size (MB): 574.71\n",
       "Estimated Total Size (MB): 1051.33\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG(cfgs[\"E\"], batch_norm=True)\n",
    "# print(model)\n",
    "from torchinfo import summary\n",
    "summary(model, input_size=(2,3,224,224), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,3,224,224)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,3,300,300)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,3,32,32)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legend13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
